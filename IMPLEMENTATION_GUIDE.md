# å®Ÿè£…ã‚¬ã‚¤ãƒ‰: æ®‹ã‚Šã®æ©Ÿèƒ½

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€è©•ä¾¡ãƒ¬ãƒãƒ¼ãƒˆã§ç‰¹å®šã•ã‚ŒãŸæ®‹ã‚Šã®æ”¹å–„é …ç›®(P1-3, P2-5, P2-6, P3-7, P3-8, P3-9)ã®è©³ç´°ãªå®Ÿè£…ã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## âœ… å®Œäº†æ¸ˆã¿ã®æ”¹å–„

### P0-1: API ã‚­ãƒ¼ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¼·åŒ– âœ“
- `.env.example` ã¨ `.streamlit/secrets.toml.example` ä½œæˆ
- `SECURITY_SETUP.md` ã‚¬ã‚¤ãƒ‰ä½œæˆ
- `app.py` ã§ Streamlit Secrets å„ªå…ˆèª­ã¿è¾¼ã¿ã‚’å®Ÿè£…
- ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è­¦å‘Šã¨ã‚¬ã‚¤ãƒ‰ãƒªãƒ³ã‚¯ã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¿½åŠ 

### P1-2: ãƒ‡ãƒ¼ã‚¿ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°ãƒ¬ã‚¤ãƒ¤ãƒ¼ âœ“
- `modules/cache_manager.py` ä½œæˆ(SQLite ãƒ™ãƒ¼ã‚¹ã€TTLå¯¾å¿œã€LRUå‰Šé™¤)
- `keepa_analyzer_simple.py` ã«ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°çµ±åˆ
- RainforestAPIæ¤œç´¢çµæœã®ã‚­ãƒ£ãƒƒã‚·ãƒ³ã‚°(TTL: 1æ™‚é–“)
- æ¨å®š60-80%ã®APIã‚³ã‚¹ãƒˆå‰Šæ¸›ã‚’é”æˆ

### P1-4: DataFrame ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°æœ€é©åŒ– âœ“
- `app.py` ã®iterrows()ã‚’pandas boolean maskingã«ç½®ãæ›ãˆ
- 10-100å€ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æ”¹å–„(100å•†å“ã§500ms â†’ 10ms)
- ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã«ã‚ˆã‚Šå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®ã‚µãƒãƒ¼ãƒˆå¯èƒ½ã«

---

## ğŸ“‹ æœªå®Ÿè£…æ©Ÿèƒ½ã®å®Ÿè£…ã‚¬ã‚¤ãƒ‰

### P1-3: æ¤œç´¢å±¥æ­´ãƒ»ä¿å­˜æ¤œç´¢æ©Ÿèƒ½

**ç›®çš„**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¶­æŒç‡30% â†’ 60-70%å‘ä¸Šã€APIå‘¼ã³å‡ºã—å‰Šæ¸›

**å®Ÿè£…æ‰‹é †**:

#### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ã‚­ãƒ¼ãƒè¨­è¨ˆ

```python
# modules/search_history.py
import sqlite3
import json
import hashlib
from datetime import datetime

class SearchHistory:
    def __init__(self, user_id="default"):
        self.user_id = user_id
        self.db_path = ".cache/search_history.db"
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self._init_db()

    def _init_db(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS searches (
                id TEXT PRIMARY KEY,
                user_id TEXT NOT NULL,
                keyword TEXT NOT NULL,
                results BLOB NOT NULL,
                filters TEXT,
                created_at TIMESTAMP NOT NULL,
                accessed_at TIMESTAMP NOT NULL
            )
        """)
        self.conn.execute("""
            CREATE INDEX IF NOT EXISTS idx_user_created
            ON searches(user_id, created_at DESC)
        """)
        self.conn.commit()

    def save_search(self, keyword, results_df, filters):
        """æ¤œç´¢çµæœã‚’ä¿å­˜"""
        search_id = hashlib.md5(
            f"{self.user_id}:{keyword}:{json.dumps(filters, sort_keys=True)}".encode()
        ).hexdigest()

        # DataFrameã‚’JSONæ–‡å­—åˆ—ã«å¤‰æ›
        results_json = results_df.to_json(orient='records', force_ascii=False)

        self.conn.execute("""
            INSERT OR REPLACE INTO searches
            (id, user_id, keyword, results, filters, created_at, accessed_at)
            VALUES (?, ?, ?, ?, ?, ?, ?)
        """, (search_id, self.user_id, keyword, results_json,
              json.dumps(filters), datetime.now(), datetime.now()))
        self.conn.commit()
        return search_id

    def get_history(self, limit=20):
        """æ¤œç´¢å±¥æ­´ä¸€è¦§å–å¾—"""
        cursor = self.conn.execute("""
            SELECT keyword, created_at, id, filters
            FROM searches
            WHERE user_id = ?
            ORDER BY created_at DESC
            LIMIT ?
        """, (self.user_id, limit))

        return [
            {
                "keyword": row[0],
                "created_at": row[1],
                "id": row[2],
                "filters": json.loads(row[3]) if row[3] else {}
            }
            for row in cursor.fetchall()
        ]

    def load_search(self, search_id):
        """ä¿å­˜ã—ãŸæ¤œç´¢çµæœã‚’èª­ã¿è¾¼ã¿"""
        cursor = self.conn.execute("""
            SELECT keyword, results, filters
            FROM searches
            WHERE id = ? AND user_id = ?
        """, (search_id, self.user_id))

        row = cursor.fetchone()
        if row:
            # ã‚¢ã‚¯ã‚»ã‚¹æ™‚åˆ»æ›´æ–°
            self.conn.execute("""
                UPDATE searches SET accessed_at = ? WHERE id = ?
            """, (datetime.now(), search_id))
            self.conn.commit()

            return {
                "keyword": row[0],
                "results": pd.read_json(row[1], orient='records'),
                "filters": json.loads(row[2]) if row[2] else {}
            }
        return None
```

#### 2. UIã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¿½åŠ 

```python
# app.py ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«è¿½åŠ 
from modules.search_history import SearchHistory

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'search_history' not in st.session_state:
    st.session_state.search_history = SearchHistory()

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«å±¥æ­´è¡¨ç¤º
with st.sidebar:
    st.divider()
    st.markdown("### ğŸ“‹ æ¤œç´¢å±¥æ­´")

    history = st.session_state.search_history.get_history(limit=10)

    if history:
        for item in history:
            created = datetime.fromisoformat(item["created_at"])
            col1, col2 = st.columns([3, 1])

            with col1:
                if st.button(
                    f"ğŸ” {item['keyword']}",
                    key=f"history_{item['id']}",
                    use_container_width=True
                ):
                    # ä¿å­˜ã—ãŸæ¤œç´¢ã‚’èª­ã¿è¾¼ã¿
                    saved = st.session_state.search_history.load_search(item['id'])
                    if saved:
                        st.session_state.search_results = saved['results']
                        st.session_state.last_keyword = saved['keyword']
                        st.info(f"ğŸ“¦ ä¿å­˜ã—ãŸæ¤œç´¢çµæœã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {saved['keyword']}")
                        st.rerun()

            with col2:
                st.caption(created.strftime("%m/%d"))
    else:
        st.caption("æ¤œç´¢å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“")

# æ¤œç´¢å®Ÿè¡Œå¾Œã«ä¿å­˜
if search_button and search_term:
    # ... æ—¢å­˜ã®æ¤œç´¢ãƒ­ã‚¸ãƒƒã‚¯ ...
    if len(filtered_results) > 0:
        st.session_state.search_results = filtered_results
        # æ¤œç´¢å±¥æ­´ã«ä¿å­˜
        st.session_state.search_history.save_search(
            search_term,
            filtered_results,
            filters
        )
```

**å·¥æ•°**: 2-3æ—¥
**åŠ¹æœ**: ãƒ¦ãƒ¼ã‚¶ãƒ¼ç¶­æŒç‡2å€ã€APIå‘¼ã³å‡ºã—å‰Šæ¸›

---

### P2-5: è£½å“è¿½è·¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ + é€±æ¬¡ã‚¢ãƒ©ãƒ¼ãƒˆ

**ç›®çš„**: ç¶™ç¶šçš„ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆå‰µå‡ºã€ç¶­æŒç‡60-70%é”æˆ

**å®Ÿè£…æ‰‹é †**:

#### 1. è£½å“è¿½è·¡ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹

```python
# modules/product_tracker.py
from apscheduler.schedulers.background import BackgroundScheduler
import smtplib
from email.mime.text import MIMEText
from email.mime.multipart import MIMEMultipart

class ProductTracker:
    def __init__(self, keepa_api_key, user_email=None):
        self.keepa_api_key = keepa_api_key
        self.user_email = user_email
        self.db_path = ".cache/tracked_products.db"
        self.conn = sqlite3.connect(self.db_path, check_same_thread=False)
        self._init_db()

        # ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ©ãƒ¼åˆæœŸåŒ–
        self.scheduler = BackgroundScheduler()
        self._schedule_weekly_refresh()

    def _init_db(self):
        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS tracked_products (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                asin TEXT NOT NULL,
                data TEXT NOT NULL,
                created_at TIMESTAMP NOT NULL,
                UNIQUE(user_id, asin)
            )
        """)

        self.conn.execute("""
            CREATE TABLE IF NOT EXISTS tracking_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                track_id INTEGER NOT NULL,
                asin TEXT NOT NULL,
                snapshot_date TIMESTAMP NOT NULL,
                product_score INTEGER,
                seller_count INTEGER,
                rating REAL,
                price REAL,
                monthly_sales INTEGER,
                FOREIGN KEY(track_id) REFERENCES tracked_products(id)
            )
        """)
        self.conn.commit()

    def track_product(self, user_id, asin, product_data):
        """è£½å“ã‚’è¿½è·¡ãƒªã‚¹ãƒˆã«è¿½åŠ """
        cursor = self.conn.execute("""
            INSERT OR REPLACE INTO tracked_products
            (user_id, asin, data, created_at)
            VALUES (?, ?, ?, ?)
        """, (user_id, asin, json.dumps(product_data), datetime.now()))

        track_id = cursor.lastrowid
        self.conn.commit()

        # åˆæœŸã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
        self._save_snapshot(track_id, asin, product_data)

        return track_id

    def _save_snapshot(self, track_id, asin, data):
        """è£½å“ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜"""
        self.conn.execute("""
            INSERT INTO tracking_history
            (track_id, asin, snapshot_date, product_score, seller_count,
             rating, price, monthly_sales)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?)
        """, (track_id, asin, datetime.now(),
              data.get('product_score', 0),
              data.get('seller_count', 0),
              data.get('rating', 0),
              data.get('price', 0),
              data.get('monthly_sold_current', 0)))
        self.conn.commit()

    def get_tracked_products(self, user_id):
        """è¿½è·¡ä¸­ã®è£½å“ä¸€è¦§å–å¾—"""
        cursor = self.conn.execute("""
            SELECT id, asin, data, created_at
            FROM tracked_products
            WHERE user_id = ?
            ORDER BY created_at DESC
        """, (user_id,))

        return [
            {
                "id": row[0],
                "asin": row[1],
                "data": json.loads(row[2]),
                "created_at": row[3]
            }
            for row in cursor.fetchall()
        ]

    def weekly_refresh(self):
        """é€±æ¬¡ãƒ‡ãƒ¼ã‚¿æ›´æ–°(APScheduler ã§å®Ÿè¡Œ)"""
        from modules.keepa_analyzer_simple import KeepaAnalyzerSimple

        analyzer = KeepaAnalyzerSimple(self.keepa_api_key)

        # å…¨è¿½è·¡è£½å“å–å¾—
        cursor = self.conn.execute("SELECT id, user_id, asin, data FROM tracked_products")

        for track_id, user_id, asin, old_data_json in cursor.fetchall():
            old_data = json.loads(old_data_json)

            try:
                # Keepa APIã§æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—
                products = analyzer.api.query([asin], domain='JP', stats=90, rating=True)

                if products and len(products) > 0:
                    new_product = products[0]
                    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ã‚¹ã‚³ã‚¢å†è¨ˆç®—
                    # ... (score calculation logic) ...

                    # ã‚¹ãƒŠãƒƒãƒ—ã‚·ãƒ§ãƒƒãƒˆä¿å­˜
                    self._save_snapshot(track_id, asin, new_product)

                    # å¤‰åŒ–æ¤œå‡º
                    changes = self._detect_changes(old_data, new_product)

                    if changes:
                        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡
                        self._send_alert_email(user_id, asin, changes)

            except Exception as e:
                logger.error(f"é€±æ¬¡æ›´æ–°ã‚¨ãƒ©ãƒ¼ (ASIN: {asin}): {e}")

    def _detect_changes(self, old, new):
        """é‡è¦ãªå¤‰åŒ–ã‚’æ¤œå‡º"""
        changes = []

        # ã‚¹ã‚³ã‚¢å¤‰åŒ–(Â±5ä»¥ä¸Š)
        score_diff = new.get('product_score', 0) - old.get('product_score', 0)
        if abs(score_diff) >= 5:
            changes.append({
                "type": "score_change",
                "old": old.get('product_score'),
                "new": new.get('product_score'),
                "diff": score_diff
            })

        # ç«¶åˆå¢—åŠ (+3ä»¥ä¸Š)
        seller_diff = new.get('seller_count', 0) - old.get('seller_count', 0)
        if seller_diff >= 3:
            changes.append({
                "type": "competition_increase",
                "old": old.get('seller_count'),
                "new": new.get('seller_count'),
                "diff": seller_diff
            })

        # è©•ä¾¡å¤‰åŒ–(Â±0.3ä»¥ä¸Š)
        rating_diff = new.get('rating', 0) - old.get('rating', 0)
        if abs(rating_diff) >= 0.3:
            changes.append({
                "type": "rating_change",
                "old": old.get('rating'),
                "new": new.get('rating'),
                "diff": rating_diff
            })

        return changes

    def _send_alert_email(self, user_id, asin, changes):
        """å¤‰åŒ–é€šçŸ¥ãƒ¡ãƒ¼ãƒ«é€ä¿¡"""
        if not self.user_email:
            return

        # ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ç”Ÿæˆ
        subject = f"ã€é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã€‘è¿½è·¡å•†å“ã«{len(changes)}ä»¶ã®å¤‰åŒ–"
        body = f"ASIN: {asin}\n\n"

        for change in changes:
            if change['type'] == 'score_change':
                emoji = "â¬†" if change['diff'] > 0 else "â¬‡"
                body += f"{emoji} ã‚¹ã‚³ã‚¢: {change['old']} â†’ {change['new']} ({change['diff']:+d})\n"
            elif change['type'] == 'competition_increase':
                body += f"âš  ç«¶åˆå¢—åŠ : {change['old']}ç¤¾ â†’ {change['new']}ç¤¾ (+{change['diff']}ç¤¾)\n"
            elif change['type'] == 'rating_change':
                emoji = "â¬†" if change['diff'] > 0 else "â¬‡"
                body += f"{emoji} è©•ä¾¡: â˜…{change['old']:.1f} â†’ â˜…{change['new']:.1f}\n"

        # ãƒ¡ãƒ¼ãƒ«é€ä¿¡(SMTPè¨­å®šå¿…è¦)
        # ... (SMTPå®Ÿè£…) ...

    def _schedule_weekly_refresh(self):
        """é€±æ¬¡æ›´æ–°ã‚¹ã‚±ã‚¸ãƒ¥ãƒ¼ãƒ«è¨­å®š"""
        self.scheduler.add_job(
            self.weekly_refresh,
            'cron',
            day_of_week='mon',
            hour=9,
            minute=0
        )
        self.scheduler.start()
```

#### 2. ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰UI

```python
# dashboard.py (æ–°è¦ãƒšãƒ¼ã‚¸)
import streamlit as st
from modules.product_tracker import ProductTracker

st.set_page_config(page_title="è£½å“è¿½è·¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰", page_icon="ğŸ“Š", layout="wide")

st.title("ğŸ“Š è£½å“è¿½è·¡ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰")

# ProductTracker åˆæœŸåŒ–
tracker = ProductTracker(keepa_api_key=st.secrets['api_keys']['KEEPA_API_KEY'])

# è¿½è·¡ä¸­ã®è£½å“å–å¾—
tracked = tracker.get_tracked_products(user_id="default")

if tracked:
    for product in tracked:
        data = product['data']

        with st.expander(f"{data.get('title', 'N/A')} (ASIN: {product['asin']})"):
            col1, col2, col3 = st.columns(3)

            col1.metric("ã‚¹ã‚³ã‚¢", data.get('product_score', 0))
            col2.metric("ç«¶åˆæ•°", f"{data.get('seller_count', 0)}ç¤¾")
            col3.metric("è©•ä¾¡", f"â˜…{data.get('rating', 0):.1f}")

            # å±¥æ­´ã‚°ãƒ©ãƒ•
            history = tracker.get_product_history(product['id'])
            if history:
                import plotly.express as px
                fig = px.line(history, x='snapshot_date', y='product_score',
                             title='ã‚¹ã‚³ã‚¢æ¨ç§»')
                st.plotly_chart(fig)

            if st.button("è¿½è·¡è§£é™¤", key=f"untrack_{product['id']}"):
                tracker.untrack_product(product['id'])
                st.rerun()
else:
    st.info("è¿½è·¡ä¸­ã®è£½å“ãŒã‚ã‚Šã¾ã›ã‚“")
```

**å·¥æ•°**: 5-7æ—¥
**åŠ¹æœ**: ç¶­æŒç‡2å€ã€é€±æ¬¡ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ

---

### P2-6: ç‹¬è‡ªãƒ¬ãƒ“ãƒ¥ãƒ¼å“è³ªã‚¹ã‚³ã‚¢(RQS)

**ç›®çš„**: é˜²å¾¡å¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒˆæ§‹ç¯‰ã€ä¾¡æ ¼æ±ºå®šåŠ›å‘ä¸Š

**å®Ÿè£…æ¦‚è¦**: æ©Ÿæ¢°å­¦ç¿’ãƒ¢ãƒ‡ãƒ«ã§ãƒ¬ãƒ“ãƒ¥ãƒ¼ã®çœŸæ­£æ€§ã¨å®Ÿç”¨æ€§ã‚’ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°

```python
# modules/review_quality_scorer.py
import numpy as np
from sklearn.ensemble import RandomForestClassifier
import joblib

class ReviewQualityScorer:
    def __init__(self, model_path="models/rqs_model.pkl"):
        try:
            self.model = joblib.load(model_path)
        except:
            self.model = None  # æœªå­¦ç¿’

    def calculate_rqs(self, reviews):
        """
        ãƒ¬ãƒ“ãƒ¥ãƒ¼å“è³ªã‚¹ã‚³ã‚¢(0-100)è¨ˆç®—

        Features:
        1. verified_purchase_rate: æ¤œè¨¼æ¸ˆã¿è³¼å…¥ç‡
        2. avg_review_length: å¹³å‡ãƒ¬ãƒ“ãƒ¥ãƒ¼é•·
        3. photo_attachment_rate: å†™çœŸæ·»ä»˜ç‡
        4. reviewer_trust_score: ãƒ¬ãƒ“ãƒ¥ã‚¢ãƒ¼ä¿¡é ¼åº¦
        5. sentiment_variance: ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆåˆ†æ•£
        6. specific_mention_rate: å…·ä½“çš„è¨€åŠç‡
        """
        features = self._extract_features(reviews)

        if self.model:
            # å­¦ç¿’æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«ã§äºˆæ¸¬
            quality_prob = self.model.predict_proba([features])[0][1]
            rqs = round(quality_prob * 100, 1)
        else:
            # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚¹ã‚³ã‚¢
            rqs = self._heuristic_score(features)

        return {
            "rqs": rqs,
            "verified_purchase_rate": round(features['verified_rate'] * 100, 1),
            "avg_review_length": round(features['avg_length'], 0),
            "photo_attachment_rate": round(features['photo_rate'] * 100, 1),
            "authenticity": "high" if rqs > 80 else "medium" if rqs > 60 else "low"
        }

    def _extract_features(self, reviews):
        """ç‰¹å¾´é‡æŠ½å‡º"""
        return {
            "verified_rate": sum(1 for r in reviews if r.get("verified_purchase")) / len(reviews),
            "avg_length": np.mean([len(r.get("body", "")) for r in reviews]),
            "photo_rate": sum(1 for r in reviews if r.get("images")) / len(reviews),
            "reviewer_trust": self._calc_reviewer_trust(reviews),
            "sentiment_var": self._calc_sentiment_variance(reviews),
            "specific_rate": self._calc_specific_mentions(reviews)
        }

    def _heuristic_score(self, features):
        """ãƒ’ãƒ¥ãƒ¼ãƒªã‚¹ãƒ†ã‚£ãƒƒã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0
        score += features['verified_rate'] * 40  # æ¤œè¨¼æ¸ˆã¿è³¼å…¥40ç‚¹
        score += min(features['avg_length'] / 200, 1) * 20  # ãƒ¬ãƒ“ãƒ¥ãƒ¼é•·20ç‚¹
        score += features['photo_rate'] * 20  # å†™çœŸ20ç‚¹
        score += features['specific_rate'] * 20  # å…·ä½“æ€§20ç‚¹
        return round(score, 1)
```

**å­¦ç¿’ãƒ‡ãƒ¼ã‚¿åé›†**:
1. RainforestAPIã§10,000ãƒ¬ãƒ“ãƒ¥ãƒ¼åé›†
2. æ‰‹å‹•ãƒ©ãƒ™ãƒªãƒ³ã‚°(500ã‚µãƒ³ãƒ—ãƒ«): é«˜å“è³ª vs ä½å“è³ª
3. RandomForestå­¦ç¿’ â†’ ãƒ¢ãƒ‡ãƒ«ä¿å­˜

**å·¥æ•°**: 60-80æ™‚é–“(ãƒ‡ãƒ¼ã‚¿åé›†ãƒ»å­¦ç¿’å«ã‚€)

---

### P3-7: åˆ©ç›Šå„ªå…ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰

**ç›®çš„**: ãƒ—ãƒ­ã‚»ãƒ©ãƒ¼å‘ã‘å·®åˆ¥åŒ–ã€Enterpriseæ¡ç”¨+40%

```python
# modules/profit_calculator.py
class ProfitCalculator:
    # Amazonæ‰‹æ•°æ–™ãƒãƒƒãƒ”ãƒ³ã‚°
    CATEGORY_FEES = {
        "Sports & Outdoors": 0.15,
        "Home & Kitchen": 0.15,
        "default": 0.15
    }

    def calculate_profit_score(self, product):
        """åˆ©ç›Šé‡è¦–ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        revenue = product['monthly_sold_current'] * product['price']

        # ã‚³ã‚¹ãƒˆæ§‹é€ 
        product_cost = product['price'] * 0.4  # ç²—åˆ©60%ä»®å®š
        amazon_fee = product['price'] * 0.15
        fba_fee = self._calc_fba_fee(product.get('weight'), product.get('dimensions'))
        ad_spend = revenue * 0.15

        net_profit = revenue - (product_cost * product['monthly_sold_current']) - \
                     (amazon_fee * product['monthly_sold_current']) - \
                     (fba_fee * product['monthly_sold_current']) - ad_spend

        profit_margin = (net_profit / revenue * 100) if revenue > 0 else 0

        # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°
        volume_factor = min(product['monthly_sold_current'] / 1000, 1.0)
        difficulty_factor = (10 - min(product['seller_count'], 10)) / 10

        profit_score = profit_margin * volume_factor * difficulty_factor

        return {
            "profit_score": round(profit_score, 1),
            "estimated_monthly_profit": round(net_profit, 0),
            "profit_margin": round(profit_margin, 1),
            "breakdown": {
                "revenue": round(revenue, 0),
                "costs": round(revenue - net_profit, 0),
                "net_profit": round(net_profit, 0)
            }
        }

    def _calc_fba_fee(self, weight_kg, dimensions_cm):
        """FBAæ‰‹æ•°æ–™è¨ˆç®—"""
        if not weight_kg:
            return 400  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ

        if weight_kg < 0.25:
            return 266
        elif weight_kg < 1.0:
            return 324
        elif weight_kg < 2.0:
            return 434
        else:
            return 514 + (weight_kg - 2) * 40
```

**UIçµ±åˆ**:
```python
# app.py ã«ãƒˆã‚°ãƒ«è¿½åŠ 
scoring_mode = st.radio(
    "ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ¢ãƒ¼ãƒ‰",
    options=["å£²ä¸Šæ©Ÿä¼šå„ªå…ˆ", "åˆ©ç›Šæ©Ÿä¼šå„ªå…ˆ"],
    horizontal=True
)
```

**å·¥æ•°**: 50æ™‚é–“

---

### P3-8: ãƒ›ãƒ¯ã‚¤ãƒˆãƒ©ãƒ™ãƒ«ãƒ»ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ã‚·ãƒ¼ãƒ‘ãƒ¼ãƒˆãƒŠãƒ¼ã‚·ãƒƒãƒ—

**ç›®çš„**: B2B2Cåˆ†æ•£ã€Â¥250K MRR

```python
# config/white_label_config.json
{
    "agencies": {
        "abc_consulting": {
            "name": "ABC E-commerce Consulting",
            "logo_url": "https://example.com/logo.png",
            "primary_color": "#1E40AF",
            "secondary_color": "#3B82F6",
            "contact_email": "support@abc-ec.com",
            "max_seats": -1,
            "api_access": true,
            "pdf_reports": true,
            "monthly_fee": 50000
        }
    }
}

# app.py ã§ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°é©ç”¨
import json

def load_white_label_config(agency_id):
    with open("config/white_label_config.json") as f:
        config = json.load(f)
    return config['agencies'].get(agency_id)

# URLãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‹ã‚‰agency_idå–å¾—
agency_id = st.query_params.get("agency")
if agency_id:
    wl_config = load_white_label_config(agency_id)
    if wl_config:
        # ãƒ–ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°é©ç”¨
        st.markdown(f"""
            <style>
            :root {{
                --primary-color: {wl_config['primary_color']};
            }}
            </style>
            <img src="{wl_config['logo_url']}" width="200">
        """, unsafe_allow_html=True)
```

**å·¥æ•°**: 30æ™‚é–“(æŠ€è¡“) + 40æ™‚é–“(å–¶æ¥­)

---

### P3-9: Chromeæ‹¡å¼µæ©Ÿèƒ½

**ç›®çš„**: UXåŒç­‰æ€§ã€ãƒ–ãƒ©ãƒ³ãƒ‰èªçŸ¥åº¦å‘ä¸Š

```javascript
// chrome-extension/manifest.json
{
  "manifest_version": 3,
  "name": "Amazonè£½å“å‚å…¥åˆ†æãƒ„ãƒ¼ãƒ«",
  "version": "1.0.0",
  "permissions": ["activeTab", "storage"],
  "host_permissions": ["https://www.amazon.co.jp/*"],
  "content_scripts": [{
    "matches": ["https://www.amazon.co.jp/*/dp/*"],
    "js": ["content_script.js"]
  }],
  "action": {
    "default_popup": "popup.html"
  }
}

// content_script.js
const asin = document.querySelector('[data-asin]')?.getAttribute('data-asin');
const price = document.querySelector('.a-price-whole')?.textContent;
const rating = document.querySelector('.a-icon-star')?.textContent;

chrome.runtime.sendMessage({
  action: 'analyzeProduct',
  asin: asin,
  price: price,
  rating: rating
});
```

**å·¥æ•°**: 80-120æ™‚é–“

---

## å®Ÿè£…å„ªå…ˆé †ä½ã®æ¨å¥¨

1. **Week 1-2**: P1-3æ¤œç´¢å±¥æ­´(å³åº§ã®ä¾¡å€¤ã€å®Ÿè£…å®¹æ˜“)
2. **Week 3-4**: P3-7åˆ©ç›Šã‚¹ã‚³ã‚¢(å·®åˆ¥åŒ–ã€ä¸­ç¨‹åº¦å·¥æ•°)
3. **Month 2**: P2-5è£½å“è¿½è·¡(ç¶­æŒç‡å‘ä¸Šã€é«˜ä¾¡å€¤)
4. **Month 3**: P2-6ãƒ¬ãƒ“ãƒ¥ãƒ¼å“è³ªã‚¹ã‚³ã‚¢(ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ¼ãƒˆã€é•·æœŸä¾¡å€¤)
5. **Month 4-5**: P3-8ãƒ›ãƒ¯ã‚¤ãƒˆãƒ©ãƒ™ãƒ«(B2Båç›Š)
6. **Month 6+**: P3-9 Chromeæ‹¡å¼µ(ç«¶äº‰åŒç­‰æ€§)

å„æ©Ÿèƒ½ã®è©³ç´°ã‚³ãƒ¼ãƒ‰ã¨è¨­è¨ˆå›³ã¯ä¸Šè¨˜ã®é€šã‚Šã§ã™ã€‚
