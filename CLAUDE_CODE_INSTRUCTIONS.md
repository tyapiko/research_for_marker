# ğŸ‹ï¸ Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« for ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨

## ğŸ“‹ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦

å¥åº·ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨ã‚’è²©å£²ã™ã‚‹ä¼æ¥­å‘ã‘ã®ã€Amazonå¸‚å ´åˆ†æï¼†å•†å“ä¼ç”»æ”¯æ´ãƒ„ãƒ¼ãƒ«ã€‚
ç«¶åˆå•†å“ã®å£²ã‚Œè¡Œããƒˆãƒ¬ãƒ³ãƒ‰ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’AIã§åˆ†æã—ã€å·®åˆ¥åŒ–ã•ã‚ŒãŸæ–°å•†å“é–‹ç™ºã‚’æ”¯æ´ã™ã‚‹ã€‚

### ğŸ¯ ä¸»ãªæ©Ÿèƒ½

1. **å¸‚å ´ãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ€¥æˆé•·ä¸­ã®ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹å•†å“ã‚’ãƒ©ãƒ³ã‚­ãƒ³ã‚°è¡¨ç¤º
2. **ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸€æ‹¬å–å¾—**: ç«¶åˆå•†å“ã®ç›´è¿‘ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŒ‡å®šä»¶æ•°ã§åé›†
3. **AIåˆ†æ**: Claude Sonnet 4.5ã§ãƒ—ãƒ­ã‚»ã‚¹åˆ¥ï¼ˆé…é€ãƒ»ä»•æ§˜ãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ç­‰ï¼‰ã«å•é¡Œç‚¹ã‚’åˆ†æ
4. **ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›**: CSV/Excelå½¢å¼ã§ãƒ‡ãƒ¼ã‚¿å‡ºåŠ›ã€æ”¹å–„ææ¡ˆã‚’å¯è¦–åŒ–

---

## ğŸ› ï¸ æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰**: Streamlit (Pythonãƒ™ãƒ¼ã‚¹ã®å¯¾è©±å‹Webã‚¢ãƒ—ãƒª)
- **ãƒ‡ãƒ¼ã‚¿åˆ†æ**: pandas, numpy, plotly
- **å¤–éƒ¨API**:
  - Keepa API: Amazonå¸‚å ´ãƒ‡ãƒ¼ã‚¿ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨ç§»ãƒ»ä¾¡æ ¼ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ï¼‰
  - RainforestAPI: Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼å…¨æ–‡å–å¾—
  - Claude API (Anthropic): AIåˆ†æãƒ»ææ¡ˆç”Ÿæˆ

---

## ğŸ“ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹æˆ

```
market/
â”œâ”€â”€ app.py                      # ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”œâ”€â”€ requirements.txt            # ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸
â”œâ”€â”€ .env                        # APIéµè¨­å®šï¼ˆgitignoreã«è¿½åŠ ï¼‰
â”œâ”€â”€ .gitignore
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ keepa_analyzer.py      # Keepaå¸‚å ´åˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â”œâ”€â”€ review_collector.py    # Rainforestãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â”‚   â””â”€â”€ claude_analyzer.py     # Claude AIåˆ†æãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
â””â”€â”€ README.md                   # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆèª¬æ˜
```

---

## ğŸ“ å®Ÿè£…æ‰‹é †

### Step 1: åˆæœŸã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

#### 1.1 ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

**requirements.txt** ã‚’ä½œæˆ:

```txt
streamlit==1.35.0
pandas==2.2.0
numpy==1.26.0
plotly==5.18.0
python-keepa==1.3.6
anthropic==0.25.0
requests==2.31.0
python-dotenv==1.0.0
openpyxl==3.1.2
```

ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã‚³ãƒãƒ³ãƒ‰:
```bash
pip install -r requirements.txt
```

#### 1.2 ç’°å¢ƒå¤‰æ•°è¨­å®š

**.env** ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆï¼ˆAPIéµã¯å¾Œã§è¨­å®šï¼‰:

```env
KEEPA_API_KEY=your_keepa_key_here
RAINFOREST_API_KEY=your_rainforest_key_here
CLAUDE_API_KEY=your_claude_key_here
```

**.gitignore** ã‚’ä½œæˆ:

```
.env
__pycache__/
*.pyc
.streamlit/
```

---

### Step 2: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«å®Ÿè£…

#### 2.1 modules/__init__.py

```python
# ç©ºãƒ•ã‚¡ã‚¤ãƒ«ã§OKï¼ˆPythonãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã¨ã—ã¦èªè­˜ã•ã›ã‚‹ï¼‰
```

#### 2.2 modules/keepa_analyzer.py

```python
"""
Keepa APIã‚’ä½¿ç”¨ã—ã¦Amazonå¸‚å ´ã®ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’è¡Œã†ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import keepa
import pandas as pd
import numpy as np
from datetime import datetime, timedelta

class KeepaAnalyzer:
    """Keepa APIåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_key):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): Keepa APIã‚­ãƒ¼
        """
        self.api = keepa.Keepa(api_key)
    
    def search_trending_products(self, keyword, min_reviews=100, min_growth=0.2, max_results=20):
        """
        ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§å£²ã‚Œç­‹å•†å“ã‚’æ¤œç´¢
        
        Args:
            keyword (str): æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: "ãƒ¨ã‚¬ãƒãƒƒãƒˆ"ï¼‰
            min_reviews (int): æœ€å°ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãƒ•ã‚£ãƒ«ã‚¿
            min_growth (float): æœ€å°æˆé•·ç‡ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆ0.2 = 20%ï¼‰
            max_results (int): æœ€å¤§çµæœæ•°
            
        Returns:
            pd.DataFrame: æ€¥æˆé•·å•†å“ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
        """
        try:
            # Keepaã§å•†å“æ¤œç´¢
            products = self.api.query(
                keyword,
                stats=180,  # éå»180æ—¥ã®ãƒ‡ãƒ¼ã‚¿
                domain='com'  # amazon.com
            )
            
            results = []
            for product in products:
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ãƒ•ã‚£ãƒ«ã‚¿
                if product.get('reviewCount', 0) < min_reviews:
                    continue
                
                # BSRï¼ˆãƒ™ã‚¹ãƒˆã‚»ãƒ©ãƒ¼ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰æ¨ç§»ã‚’å–å¾—
                bsr_history = product['data'].get('SALES_rank', [])
                if len(bsr_history) < 60:  # æœ€ä½60æ—¥åˆ†ã®ãƒ‡ãƒ¼ã‚¿ãŒå¿…è¦
                    continue
                
                # æˆé•·ç‡è¨ˆç®—ï¼ˆãƒ©ãƒ³ã‚­ãƒ³ã‚°ãŒä¸‹ãŒã‚‹ = å£²ä¸Šä¸Šæ˜‡ï¼‰
                recent_avg = np.mean(bsr_history[-30:]) if len(bsr_history) >= 30 else None
                past_avg = np.mean(bsr_history[-90:-60]) if len(bsr_history) >= 90 else None
                
                if recent_avg and past_avg and past_avg > 0:
                    growth_rate = (past_avg - recent_avg) / past_avg
                    
                    if growth_rate >= min_growth:
                        # æ—¥ä»˜é…åˆ—ã‚’ç”Ÿæˆï¼ˆKeepaTimeå½¢å¼ã‹ã‚‰datetimeã«å¤‰æ›ï¼‰
                        keepa_time_minutes = product['data'].get('SALES_time', [])
                        dates = [
                            datetime(2011, 1, 1) + timedelta(minutes=int(t))
                            for t in keepa_time_minutes
                        ]
                        
                        results.append({
                            'asin': product['asin'],
                            'title': product.get('title', 'N/A'),
                            'growth_rate': growth_rate,
                            'review_count': product.get('reviewCount', 0),
                            'rating': product.get('rating', 0) / 10,  # Keepaã¯10å€ã‚¹ã‚±ãƒ¼ãƒ«
                            'price': product['data']['NEW'][-1] / 100 if 'NEW' in product['data'] else 0,
                            'current_rank': bsr_history[-1] if bsr_history else 0,
                            'bsr_history': bsr_history,
                            'bsr_history_dates': dates
                        })
            
            df = pd.DataFrame(results)
            if len(df) == 0:
                return pd.DataFrame()
            
            return df.sort_values('growth_rate', ascending=False).head(max_results)
        
        except Exception as e:
            raise Exception(f"Keepaæ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
```

#### 2.3 modules/review_collector.py

```python
"""
RainforestAPIã‚’ä½¿ç”¨ã—ã¦Amazonãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—ã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import requests
import time
from typing import List, Dict, Callable, Optional

class ReviewCollector:
    """RainforestAPI ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_key):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): RainforestAPI APIã‚­ãƒ¼
        """
        self.api_key = api_key
        self.base_url = 'https://api.rainforestapi.com/request'
    
    def collect_reviews(
        self, 
        asin: str, 
        target_count: int, 
        progress_callback: Optional[Callable] = None
    ) -> List[Dict]:
        """
        æŒ‡å®šASINã®ç›´è¿‘ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’å–å¾—
        
        Args:
            asin (str): Amazonå•†å“ID (ASIN)
            target_count (int): å–å¾—ç›®æ¨™ä»¶æ•°
            progress_callback (callable): ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼æ›´æ–°ç”¨ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯é–¢æ•°
            
        Returns:
            List[Dict]: ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆ
        """
        reviews = []
        page = 1
        
        # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹ãƒãƒ¼åˆæœŸåŒ–
        if progress_callback:
            progress_bar = progress_callback(0)
        
        try:
            while len(reviews) < target_count:
                params = {
                    'api_key': self.api_key,
                    'type': 'reviews',
                    'amazon_domain': 'amazon.com',
                    'asin': asin,
                    'page': page,
                    'sort_by': 'recent'  # ç›´è¿‘é †ã«ã‚½ãƒ¼ãƒˆ
                }
                
                response = requests.get(self.base_url, params=params, timeout=30)
                
                if response.status_code != 200:
                    print(f"è­¦å‘Š: ãƒšãƒ¼ã‚¸{page}ã®å–å¾—å¤±æ•— (Status: {response.status_code})")
                    break
                
                data = response.json()
                
                # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                for review in data.get('reviews', []):
                    if len(reviews) >= target_count:
                        break
                    
                    reviews.append({
                        'asin': asin,
                        'review_id': review.get('id', ''),
                        'rating': review.get('rating', 0),
                        'title': review.get('title', ''),
                        'body': review.get('body', ''),
                        'verified_purchase': review.get('verified_purchase', False),
                        'date': review.get('date', {}).get('raw', ''),
                        'helpful_votes': review.get('helpful_votes', 0),
                        'images': len(review.get('images', []))
                    })
                    
                    # ãƒ—ãƒ­ã‚°ãƒ¬ã‚¹æ›´æ–°
                    if progress_callback:
                        progress_bar.progress(len(reviews) / target_count)
                
                # æ¬¡ãƒšãƒ¼ã‚¸ãŒãªã„å ´åˆã¯çµ‚äº†
                if not data.get('pagination', {}).get('next_page_link'):
                    break
                
                page += 1
                time.sleep(0.5)  # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾ç­–
            
            return reviews
        
        except Exception as e:
            raise Exception(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
```

#### 2.4 modules/claude_analyzer.py

```python
"""
Claude APIã‚’ä½¿ç”¨ã—ã¦ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æã™ã‚‹ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""
import anthropic
import json
import pandas as pd
from typing import Dict

class ClaudeAnalyzer:
    """Claude AIåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, api_key):
        """
        åˆæœŸåŒ–
        
        Args:
            api_key (str): Anthropic Claude APIã‚­ãƒ¼
        """
        self.client = anthropic.Anthropic(api_key=api_key)
    
    def analyze_reviews(self, reviews_df: pd.DataFrame) -> Dict:
        """
        ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ãƒ—ãƒ­ã‚»ã‚¹åˆ¥ã«åˆ†æ
        
        Args:
            reviews_df (pd.DataFrame): ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ 
            
        Returns:
            Dict: åˆ†æçµæœï¼ˆã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œã€æ”¹å–„ææ¡ˆã€æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆï¼‰
        """
        # ä½è©•ä¾¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’æŠ½å‡ºï¼ˆâ˜…3ä»¥ä¸‹ï¼‰
        negative_reviews = reviews_df[reviews_df['rating'] <= 3]
        
        if len(negative_reviews) == 0:
            return {
                "ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œ": {},
                "æ”¹å–„ææ¡ˆ": [],
                "æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆ": {}
            }
        
        # ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°ï¼ˆæœ€å¤§300ä»¶ã€ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
        sampled = negative_reviews.sample(
            n=min(300, len(negative_reviews))
        )
        
        # ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ†ã‚­ã‚¹ãƒˆã‚’æ•´å½¢
        review_text = "\n\n---\n\n".join([
            f"â˜…{row['rating']} | {row['date']}\n"
            f"ã‚¿ã‚¤ãƒˆãƒ«: {row['title']}\n"
            f"æœ¬æ–‡: {row['body']}"
            for _, row in sampled.iterrows()
        ])
        
        prompt = f"""
ã‚ãªãŸã¯ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨ãƒ¡ãƒ¼ã‚«ãƒ¼ã®å•†å“ä¼ç”»ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆã§ã™ã€‚
ç«¶åˆå•†å“ã®ä½è©•ä¾¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åˆ†æã—ã€**ãƒ—ãƒ­ã‚»ã‚¹åˆ¥**ã«å•é¡Œç‚¹ã‚’æ•´ç†ã—ã¦ãã ã•ã„ã€‚

## åˆ†æå¯¾è±¡ãƒ¬ãƒ“ãƒ¥ãƒ¼ï¼ˆ{len(sampled)}ä»¶ï¼‰
{review_text}

## åˆ†ææŒ‡ç¤º
ä»¥ä¸‹ã®ã‚«ãƒ†ã‚´ãƒªã«åˆ†é¡ã—ã¦å•é¡Œç‚¹ã‚’æŠ½å‡ºã—ã¦ãã ã•ã„ï¼š

1. **é…é€ãƒ»æ¢±åŒ…**: é…é€é…å»¶ã€ç ´æã€æ¢±åŒ…ä¸è‰¯ãªã©
2. **å•†å“ä»•æ§˜**: ã‚µã‚¤ã‚ºã€é‡é‡ã€ç´ æã€æ©Ÿèƒ½ä¸è¶³ãªã©
3. **ãƒ‡ã‚¶ã‚¤ãƒ³**: è¦‹ãŸç›®ã€è‰²ã€ä½¿ã„ã‚„ã™ã•ãªã©
4. **å“è³ªãƒ»è€ä¹…æ€§**: æ•…éšœã€åŠ£åŒ–ã€ä¸è‰¯å“ãªã©
5. **ã‚µãƒ¼ãƒ“ã‚¹**: è¿”å“å¯¾å¿œã€ã‚«ã‚¹ã‚¿ãƒãƒ¼ã‚µãƒãƒ¼ãƒˆãªã©
6. **ä¾¡æ ¼ãƒ»ã‚³ã‚¹ãƒ‘**: ä¾¡æ ¼ã«è¦‹åˆã‚ãªã„ã€é«˜ã™ãã‚‹ãªã©

## å‡ºåŠ›JSONå½¢å¼
```json
{{
  "ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œ": {{
    "é…é€ãƒ»æ¢±åŒ…": [
      {{"å•é¡Œ": "å…·ä½“çš„ãªå•é¡Œå†…å®¹", "é »åº¦": "é«˜", "å…·ä½“ä¾‹": "ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‹ã‚‰ã®å¼•ç”¨"}}
    ],
    "å•†å“ä»•æ§˜": [...],
    "ãƒ‡ã‚¶ã‚¤ãƒ³": [...],
    "å“è³ªãƒ»è€ä¹…æ€§": [...],
    "ã‚µãƒ¼ãƒ“ã‚¹": [...],
    "ä¾¡æ ¼ãƒ»ã‚³ã‚¹ãƒ‘": [...]
  }},
  "æ”¹å–„ææ¡ˆ": [
    {{
      "ææ¡ˆ": "å…·ä½“çš„ãªæ”¹å–„æ¡ˆ",
      "è§£æ±ºã™ã‚‹å•é¡Œ": "å¯¾å¿œã™ã‚‹ã‚«ãƒ†ã‚´ãƒªã¨å•é¡Œ",
      "å®Ÿç¾å¯èƒ½æ€§": "é«˜",
      "å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ": "ç«¶åˆã¨ã®é•ã„",
      "æƒ³å®šã‚³ã‚¹ãƒˆå½±éŸ¿": "ã‚³ã‚¹ãƒˆå¢—æ¸›ã®è¦‹è¾¼ã¿"
    }}
  ],
  "æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆ": {{
    "å•†å“åæ¡ˆ": "é­…åŠ›çš„ãªå•†å“å",
    "ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¡§å®¢": "å…·ä½“çš„ãªãƒšãƒ«ã‚½ãƒŠ",
    "USP": "ä»–ç¤¾ã«ãªã„ç‹¬è‡ªã®ä¾¡å€¤",
    "æƒ³å®šä¾¡æ ¼å¸¯": "$XX - $XX",
    "ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸": "é¡§å®¢ã«åˆºã•ã‚‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"
  }}
}}
```

**é‡è¦**: å¿…ãšJSONå½¢å¼ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚èª¬æ˜æ–‡ã¯ä¸è¦ã§ã™ã€‚
"""
        
        try:
            message = self.client.messages.create(
                model="claude-sonnet-4-5-20250929",
                max_tokens=8000,
                temperature=0.3,
                messages=[{"role": "user", "content": prompt}]
            )
            
            # JSONæŠ½å‡ºï¼ˆãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³è¨˜æ³•ã‚’é™¤å»ï¼‰
            response_text = message.content[0].text
            json_text = response_text.replace('```json', '').replace('```', '').strip()
            
            analysis = json.loads(json_text)
            return analysis
        
        except Exception as e:
            raise Exception(f"Claudeåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
```

---

### Step 3: ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè£…

#### 3.1 app.py

```python
"""
Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« for ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨
ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
"""
import streamlit as st
import pandas as pd
import plotly.express as px
from dotenv import load_dotenv
import os

# ã‚«ã‚¹ã‚¿ãƒ ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
from modules.keepa_analyzer import KeepaAnalyzer
from modules.review_collector import ReviewCollector
from modules.claude_analyzer import ClaudeAnalyzer

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ«",
    page_icon="ğŸ‹ï¸",
    layout="wide"
)

# ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹åˆæœŸåŒ–
if 'search_results' not in st.session_state:
    st.session_state.search_results = None
if 'collected_reviews' not in st.session_state:
    st.session_state.collected_reviews = {}
if 'analysis' not in st.session_state:
    st.session_state.analysis = None

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ï¼šAPIè¨­å®š
with st.sidebar:
    st.title("âš™ï¸ è¨­å®š")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ or ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    keepa_key = st.text_input(
        "Keepa API Key", 
        value=os.getenv('KEEPA_API_KEY', ''),
        type="password"
    )
    rainforest_key = st.text_input(
        "RainforestAPI Key",
        value=os.getenv('RAINFOREST_API_KEY', ''),
        type="password"
    )
    claude_key = st.text_input(
        "Claude API Key",
        value=os.getenv('CLAUDE_API_KEY', ''),
        type="password"
    )
    
    st.divider()
    st.markdown("### ğŸ“Š å–å¾—çŠ¶æ³")
    total_reviews = sum(len(r) for r in st.session_state.collected_reviews.values())
    st.metric("å–å¾—æ¸ˆã¿ãƒ¬ãƒ“ãƒ¥ãƒ¼", f"{total_reviews:,}ä»¶")
    st.metric("åˆ†ææ¸ˆã¿å•†å“", f"{len(st.session_state.collected_reviews)}å€‹")

# ãƒ¡ã‚¤ãƒ³ã‚¨ãƒªã‚¢
st.title("ğŸ‹ï¸ Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« for ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹")
st.markdown("ç«¶åˆå•†å“ã®å£²ã‚Œè¡Œããƒˆãƒ¬ãƒ³ãƒ‰ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’AIåˆ†æã—ã€å·®åˆ¥åŒ–ã•ã‚ŒãŸæ–°å•†å“é–‹ç™ºã‚’æ”¯æ´ã—ã¾ã™ã€‚")

# æ¤œç´¢ã‚»ã‚¯ã‚·ãƒ§ãƒ³
st.divider()
col1, col2 = st.columns([3, 1])
with col1:
    search_term = st.text_input(
        "å•†å“ã‚«ãƒ†ã‚´ãƒªã‚’æ¤œç´¢",
        placeholder="ä¾‹: ãƒ¨ã‚¬ãƒãƒƒãƒˆ, ãƒ€ãƒ³ãƒ™ãƒ«, ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹ãƒãƒ³ãƒ‰",
        help="Amazonã§æ¤œç´¢ã—ãŸã„ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å…¥åŠ›"
    )
with col2:
    st.write("")  # ã‚¹ãƒšãƒ¼ã‚¹èª¿æ•´
    st.write("")
    search_button = st.button("ğŸ” æ¤œç´¢", type="primary", use_container_width=True)

# æ¤œç´¢å®Ÿè¡Œ
if search_button and search_term:
    if not keepa_key:
        st.error("âŒ Keepa APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„")
    else:
        with st.spinner("å¸‚å ´åˆ†æä¸­... Keepa APIã§ãƒˆãƒ¬ãƒ³ãƒ‰å•†å“ã‚’æ¤œç´¢ã—ã¦ã„ã¾ã™"):
            try:
                analyzer = KeepaAnalyzer(keepa_key)
                results = analyzer.search_trending_products(search_term)
                
                if len(results) > 0:
                    st.session_state.search_results = results
                    st.success(f"âœ… {len(results)}ä»¶ã®æ€¥æˆé•·å•†å“ã‚’ç™ºè¦‹ã—ã¾ã—ãŸï¼")
                else:
                    st.warning("âš ï¸ æ¡ä»¶ã«åˆã†å•†å“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦ã¿ã¦ãã ã•ã„ã€‚")
            except Exception as e:
                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

# çµæœè¡¨ç¤º
if st.session_state.search_results is not None and len(st.session_state.search_results) > 0:
    st.divider()
    st.subheader("ğŸ“Š å£²ã‚Œç­‹ãƒˆãƒ¬ãƒ³ãƒ‰ï¼ˆæˆé•·ç‡é †ï¼‰")
    
    for idx, (_, row) in enumerate(st.session_state.search_results.iterrows(), 1):
        with st.container():
            col1, col2, col3 = st.columns([3, 2, 2])
            
            with col1:
                st.markdown(f"### {idx}. {row['title'][:60]}...")
                st.caption(f"ASIN: {row['asin']}")
                
                # ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
                metric_col1, metric_col2, metric_col3 = st.columns(3)
                with metric_col1:
                    st.metric("è©•ä¾¡", f"â­ {row['rating']:.1f}")
                with metric_col2:
                    st.metric("ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{row['review_count']:,}ä»¶")
                with metric_col3:
                    st.metric("ä¾¡æ ¼", f"${row['price']:.2f}")
                
                # æˆé•·ç‡ãƒãƒƒã‚¸
                growth = row['growth_rate'] * 100
                st.markdown(
                    f"<div style='background-color: #00ff00; padding: 8px; border-radius: 5px; "
                    f"text-align: center; font-weight: bold;'>"
                    f"ğŸ“ˆ æˆé•·ç‡: {growth:.1f}%</div>",
                    unsafe_allow_html=True
                )
            
            with col2:
                # ãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨ç§»ã‚°ãƒ©ãƒ•
                if 'bsr_history' in row and len(row['bsr_history']) > 0:
                    fig = px.line(
                        x=row['bsr_history_dates'][-90:],  # ç›´è¿‘90æ—¥
                        y=row['bsr_history'][-90:],
                        title="å£²ä¸Šãƒ©ãƒ³ã‚­ãƒ³ã‚°æ¨ç§»ï¼ˆä½ã„ã»ã©å£²ã‚Œã¦ã„ã‚‹ï¼‰"
                    )
                    fig.update_layout(
                        height=200, 
                        showlegend=False,
                        xaxis_title="",
                        yaxis_title="ãƒ©ãƒ³ã‚­ãƒ³ã‚°"
                    )
                    st.plotly_chart(fig, use_container_width=True)
            
            with col3:
                st.markdown("**ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—**")
                review_count = st.number_input(
                    "å–å¾—ä»¶æ•°",
                    min_value=100,
                    max_value=1000,
                    value=500,
                    step=100,
                    key=f"count_{row['asin']}",
                    help="å–å¾—ã™ã‚‹ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°ï¼ˆç›´è¿‘ã‹ã‚‰ï¼‰"
                )
                
                # å–å¾—ãƒœã‚¿ãƒ³
                if st.button(
                    f"ğŸ“¥ ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—", 
                    key=f"btn_{row['asin']}", 
                    use_container_width=True,
                    disabled=not rainforest_key
                ):
                    if not rainforest_key:
                        st.error("RainforestAPI KeyãŒå¿…è¦ã§ã™")
                    else:
                        with st.spinner(f"ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ä¸­... (0/{review_count})"):
                            try:
                                collector = ReviewCollector(rainforest_key)
                                reviews = collector.collect_reviews(
                                    row['asin'],
                                    review_count,
                                    progress_callback=st.progress
                                )
                                st.session_state.collected_reviews[row['asin']] = reviews
                                st.success(f"âœ… {len(reviews)}ä»¶å–å¾—å®Œäº†ï¼")
                                st.rerun()
                            except Exception as e:
                                st.error(f"âŒ ã‚¨ãƒ©ãƒ¼: {str(e)}")
                
                # æ—¢ã«å–å¾—æ¸ˆã¿ãªã‚‰è¡¨ç¤º
                if row['asin'] in st.session_state.collected_reviews:
                    count = len(st.session_state.collected_reviews[row['asin']])
                    st.success(f"âœ… {count}ä»¶å–å¾—æ¸ˆã¿")
            
            st.divider()

# åˆ†æã‚»ã‚¯ã‚·ãƒ§ãƒ³
if st.session_state.collected_reviews and claude_key:
    st.divider()
    st.subheader("ğŸ¤– AIåˆ†æ")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        if st.button("ğŸ“Š ä¸€æ‹¬åˆ†æé–‹å§‹", type="primary", use_container_width=True):
            with st.spinner("Claude Sonnet 4.5ã§åˆ†æä¸­... æ•°åç§’ã‹ã‹ã‚Šã¾ã™"):
                try:
                    # å…¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’çµ±åˆ
                    all_reviews = []
                    for asin, reviews in st.session_state.collected_reviews.items():
                        all_reviews.extend(reviews)
                    
                    df_reviews = pd.DataFrame(all_reviews)
                    
                    # Claudeåˆ†æ
                    analyzer = ClaudeAnalyzer(claude_key)
                    analysis = analyzer.analyze_reviews(df_reviews)
                    
                    st.session_state.analysis = analysis
                    st.success("âœ… åˆ†æå®Œäº†ï¼ä¸‹ã«ã‚¹ã‚¯ãƒ­ãƒ¼ãƒ«ã—ã¦çµæœã‚’ç¢ºèªã—ã¦ãã ã•ã„")
                    st.rerun()
                except Exception as e:
                    st.error(f"âŒ åˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
    
    with col2:
        if st.button("ğŸ“„ CSVå‡ºåŠ›", use_container_width=True):
            # CSVç”Ÿæˆ
            all_reviews_df = pd.DataFrame([
                r for reviews in st.session_state.collected_reviews.values() 
                for r in reviews
            ])
            
            csv = all_reviews_df.to_csv(index=False).encode('utf-8-sig')
            st.download_button(
                "ğŸ’¾ CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                csv,
                "amazon_reviews.csv",
                "text/csv",
                use_container_width=True
            )
    
    with col3:
        if st.button("ğŸ”„ ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªã‚¢", use_container_width=True):
            st.session_state.collected_reviews = {}
            st.session_state.analysis = None
            st.success("âœ… ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸ")
            st.rerun()

# åˆ†æçµæœè¡¨ç¤º
if st.session_state.analysis:
    st.divider()
    st.header("ğŸ“ˆ AIåˆ†æçµæœ")
    
    analysis = st.session_state.analysis
    
    # ã‚¿ãƒ–ã§è¡¨ç¤º
    tab1, tab2, tab3, tab4 = st.tabs([
        "ğŸ“Š ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œç‚¹",
        "ğŸ’¡ æ”¹å–„ææ¡ˆ",
        "ğŸ¯ æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆ",
        "ğŸ“ˆ è©³ç´°ãƒ‡ãƒ¼ã‚¿"
    ])
    
    with tab1:
        st.subheader("ãƒ—ãƒ­ã‚»ã‚¹åˆ¥å•é¡Œç‚¹åˆ†æ")
        
        categories = analysis.get('ã‚«ãƒ†ã‚´ãƒªåˆ¥å•é¡Œ', {})
        
        for category, issues in categories.items():
            if len(issues) > 0:
                with st.expander(f"**{category}** ({len(issues)}ä»¶)", expanded=True):
                    for issue in issues:
                        col1, col2 = st.columns([3, 1])
                        with col1:
                            st.markdown(f"**{issue['å•é¡Œ']}**")
                            st.caption(f"å…·ä½“ä¾‹: {issue['å…·ä½“ä¾‹'][:150]}...")
                        with col2:
                            freq_color = {
                                'é«˜': 'ğŸ”´',
                                'ä¸­': 'ğŸŸ¡',
                                'ä½': 'ğŸŸ¢'
                            }
                            freq = issue.get('é »åº¦', 'ä¸­')
                            st.markdown(f"{freq_color.get(freq, 'âšª')} é »åº¦: {freq}")
    
    with tab2:
        st.subheader("ğŸ’¡ æ”¹å–„ææ¡ˆ")
        
        proposals = analysis.get('æ”¹å–„ææ¡ˆ', [])
        
        for idx, proposal in enumerate(proposals, 1):
            with st.container():
                col1, col2 = st.columns([3, 1])
                with col1:
                    st.markdown(f"### {idx}. {proposal['ææ¡ˆ']}")
                    st.markdown(f"**è§£æ±ºã™ã‚‹å•é¡Œ:** {proposal['è§£æ±ºã™ã‚‹å•é¡Œ']}")
                    st.markdown(f"**å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ:** {proposal['å·®åˆ¥åŒ–ãƒã‚¤ãƒ³ãƒˆ']}")
                with col2:
                    st.metric("å®Ÿç¾å¯èƒ½æ€§", proposal['å®Ÿç¾å¯èƒ½æ€§'])
                    st.caption(f"ã‚³ã‚¹ãƒˆå½±éŸ¿: {proposal['æƒ³å®šã‚³ã‚¹ãƒˆå½±éŸ¿']}")
                st.divider()
    
    with tab3:
        st.subheader("ğŸ¯ æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆ")
        concept = analysis.get('æ–°å•†å“ã‚³ãƒ³ã‚»ãƒ—ãƒˆ', {})
        
        if concept:
            col1, col2 = st.columns(2)
            with col1:
                st.metric("å•†å“åæ¡ˆ", concept.get('å•†å“åæ¡ˆ', 'N/A'))
                st.metric("æƒ³å®šä¾¡æ ¼å¸¯", concept.get('æƒ³å®šä¾¡æ ¼å¸¯', 'N/A'))
            with col2:
                st.metric("ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¡§å®¢", concept.get('ã‚¿ãƒ¼ã‚²ãƒƒãƒˆé¡§å®¢', 'N/A'))
            
            st.markdown("### ğŸ–ï¸ USP (ç‹¬è‡ªã®å¼·ã¿)")
            st.info(concept.get('USP', 'N/A'))
            
            st.markdown("### ğŸ“¢ ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
            st.success(concept.get('ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸', 'N/A'))
    
    with tab4:
        # è©³ç´°ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
        st.subheader("ğŸ“ˆ è©³ç´°ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ‡ãƒ¼ã‚¿")
        
        all_reviews_df = pd.DataFrame([
            r for reviews in st.session_state.collected_reviews.values() 
            for r in reviews
        ])
        
        # è©•ä¾¡åˆ†å¸ƒ
        col1, col2 = st.columns(2)
        
        with col1:
            fig = px.histogram(
                all_reviews_df,
                x='rating',
                title="è©•ä¾¡åˆ†å¸ƒ",
                labels={'rating': 'è©•ä¾¡', 'count': 'ä»¶æ•°'},
                nbins=5
            )
            st.plotly_chart(fig, use_container_width=True)
        
        with col2:
            # è©•ä¾¡çµ±è¨ˆ
            st.markdown("### ğŸ“Š çµ±è¨ˆæƒ…å ±")
            st.metric("å¹³å‡è©•ä¾¡", f"{all_reviews_df['rating'].mean():.2f}")
            st.metric("ç·ãƒ¬ãƒ“ãƒ¥ãƒ¼æ•°", f"{len(all_reviews_df):,}ä»¶")
            st.metric("ä½è©•ä¾¡(â˜…3ä»¥ä¸‹)", f"{len(all_reviews_df[all_reviews_df['rating'] <= 3]):,}ä»¶")
        
        # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«
        st.markdown("### ğŸ“‹ ãƒ¬ãƒ“ãƒ¥ãƒ¼ä¸€è¦§")
        st.dataframe(
            all_reviews_df[['asin', 'rating', 'title', 'date', 'verified_purchase']],
            use_container_width=True,
            height=400
        )

# ãƒ•ãƒƒã‚¿ãƒ¼
st.divider()
st.markdown("""
<div style='text-align: center; color: gray;'>
<p>Powered by Keepa API | RainforestAPI | Claude Sonnet 4.5</p>
<p>Â© 2025 Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« for ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹</p>
</div>
""", unsafe_allow_html=True)
```

---

### Step 4: READMEä½œæˆ

#### README.md

```markdown
# ğŸ‹ï¸ Amazonç«¶åˆåˆ†æãƒ„ãƒ¼ãƒ« for ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹æ©Ÿå™¨

ç«¶åˆå•†å“ã®å£²ã‚Œè¡Œããƒˆãƒ¬ãƒ³ãƒ‰ã¨ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’AIåˆ†æã—ã€å·®åˆ¥åŒ–ã•ã‚ŒãŸæ–°å•†å“é–‹ç™ºã‚’æ”¯æ´ã™ã‚‹ãƒ„ãƒ¼ãƒ«ã€‚

## ğŸš€ ã‚¯ã‚¤ãƒƒã‚¯ã‚¹ã‚¿ãƒ¼ãƒˆ

### 1. ä¾å­˜ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

\`\`\`bash
pip install -r requirements.txt
\`\`\`

### 2. APIéµã®è¨­å®š

`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã€ä»¥ä¸‹ã‚’è¨˜å…¥ï¼š

\`\`\`env
KEEPA_API_KEY=your_keepa_api_key_here
RAINFOREST_API_KEY=your_rainforest_api_key_here
CLAUDE_API_KEY=your_claude_api_key_here
\`\`\`

**APIå–å¾—æ–¹æ³•ï¼š**
- **Keepa**: https://keepa.com/ (â‚¬19/æœˆ)
- **RainforestAPI**: https://www.rainforestapi.com/ ($47/æœˆã€œ)
- **Claude**: https://console.anthropic.com/ (å¾“é‡èª²é‡‘)

### 3. ã‚¢ãƒ—ãƒªèµ·å‹•

\`\`\`bash
streamlit run app.py
\`\`\`

ãƒ–ãƒ©ã‚¦ã‚¶ã§ `http://localhost:8501` ãŒè‡ªå‹•ã§é–‹ãã¾ã™ã€‚

## ğŸ“‹ ä½¿ã„æ–¹

1. **æ¤œç´¢**: ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆä¾‹: "ãƒ¨ã‚¬ãƒãƒƒãƒˆ"ï¼‰ã§æ€¥æˆé•·å•†å“ã‚’æ¤œç´¢
2. **ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—**: å„å•†å“ã®ã€Œãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã€ãƒœã‚¿ãƒ³ã§ç›´è¿‘ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’åé›†
3. **AIåˆ†æ**: ã€Œä¸€æ‹¬åˆ†æé–‹å§‹ã€ã§å•é¡Œç‚¹ãƒ»æ”¹å–„ææ¡ˆã‚’ç”Ÿæˆ
4. **ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›**: CSV/Excelå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰

## ğŸ’° ã‚³ã‚¹ãƒˆè©¦ç®—

| é …ç›® | æ–™é‡‘ |
|------|------|
| Keepa API | â‚¬19/æœˆ |
| RainforestAPI | $47/æœˆï¼ˆ10,000ãƒªã‚¯ã‚¨ã‚¹ãƒˆï¼‰ |
| Claude API | $0.18/åˆ†æ |

**ä¾‹**: 5å•†å“Ã—500ãƒ¬ãƒ“ãƒ¥ãƒ¼åˆ†æ = ç´„$80/æœˆ

## ğŸ› ï¸ ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚¨ãƒ©ãƒ¼: "Keepaæ¤œç´¢ã‚¨ãƒ©ãƒ¼"
â†’ APIã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã€‚Keepaã‚¢ã‚«ã‚¦ãƒ³ãƒˆã®æœ‰åŠ¹æœŸé™ã‚’ãƒã‚§ãƒƒã‚¯ã€‚

### ã‚¨ãƒ©ãƒ¼: "ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ã‚¨ãƒ©ãƒ¼"
â†’ RainforestAPIã®æœˆé–“ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¸Šé™ã‚’ç¢ºèªã€‚

### åˆ†æãŒé€”ä¸­ã§æ­¢ã¾ã‚‹
â†’ Claude APIã®ãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™ã®å¯èƒ½æ€§ã€‚ãƒ¬ãƒ“ãƒ¥ãƒ¼ä»¶æ•°ã‚’æ¸›ã‚‰ã—ã¦å†è©¦è¡Œã€‚

## ğŸ“„ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License
```

---

## âœ… å®Ÿè£…å®Œäº†å¾Œã®ç¢ºèªäº‹é …

### 1. ãƒ­ãƒ¼ã‚«ãƒ«ãƒ†ã‚¹ãƒˆ
```bash
# ä»®æƒ³ç’°å¢ƒä½œæˆï¼ˆæ¨å¥¨ï¼‰
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install -r requirements.txt

# ã‚¢ãƒ—ãƒªèµ·å‹•
streamlit run app.py
```

### 2. APIéµã®ãƒ†ã‚¹ãƒˆ
- Keepa: æ¤œç´¢æ©Ÿèƒ½ãŒå‹•ä½œã™ã‚‹ã‹
- RainforestAPI: ãƒ¬ãƒ“ãƒ¥ãƒ¼å–å¾—ãŒå‹•ä½œã™ã‚‹ã‹
- Claude: åˆ†æãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹ã‹

### 3. ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ç¢ºèª
- APIéµæœªå…¥åŠ›æ™‚ã®ã‚¨ãƒ©ãƒ¼è¡¨ç¤º
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚¨ãƒ©ãƒ¼æ™‚ã®å‹•ä½œ
- ç•°å¸¸ãªãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚ã®å‡¦ç†

---

## ğŸ“ PBLæ•™æåŒ–ã®ãƒã‚¤ãƒ³ãƒˆ

### Week 1: ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—
- Pythonç’°å¢ƒæ§‹ç¯‰
- StreamlitåŸºç¤
- APIç™»éŒ²ãƒ»èªè¨¼

### Week 2: ãƒ‡ãƒ¼ã‚¿åé›†
- Keepa APIã®ç†è§£
- RainforestAPIã®çµ±åˆ
- ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

### Week 3: AIåˆ†æ
- Claude APIãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°
- JSONæ§‹é€ åŒ–å‡ºåŠ›
- çµæœã®å¯è¦–åŒ–

### Week 4: å®Ÿå‹™é©ç”¨
- å®Ÿéš›ã®å•†å“ã§åˆ†æ
- ãƒ“ã‚¸ãƒã‚¹ææ¡ˆæ›¸ä½œæˆ
- ROIè¨ˆç®—

---

## ğŸ“ ã‚µãƒãƒ¼ãƒˆ

è³ªå•ãƒ»ãƒã‚°å ±å‘Šã¯GitHub Issuesã¾ã§ã€‚